Interfaces
==========

The :mod:`gim_cv.interfaces` submodule is a relatively low-level submodule 
responsible for providing interfaces which perform:

* The extraction of `Dask arrays`_ (containing the raw numerical grid data)
  from raster and shape files.

* The writing of output arrays (containing e.g. inference results) back to raster 
  files.

This is a necessary intermediate step linking the source data files to preprocessing 
pipelines for training and inference, and for writing mask arrays during inference 
back to raster files.

Currently supported is the extraction/writing of image and mask arrays from/to 
multi-channel rasters, and reading single-channel masks from shapefiles.

For an end-user it is *not necessary to understand the details* of this, as this 
logic is dealt with by the :class:`~gim_cv.training.TrainingDataset` and 
:class:`~gim_cv.inference.InferenceDataset` classes, so you can skip to 
:doc:`preprocessing`. Note however that it is **highly recommended** 
to use ``.tif`` format for rasters (these are much faster to read/write to which 
speeds up training and inference massively with respect to ``.jp2``). It is 
currently also **necessary** to use ``.shp`` format for vector mask data. 

Reading files
-------------

The necessary interface class for a given file extension can be obtained with the 
function :func:`~gim_cv.interfaces.get_interface`. For example::

    # get the appropriate classes for reading from tif and shapefiles
    tif_reader = get_interface('raster.tif', 'ImageReader')
    shp_reader = get_interface('vector_mask.shp', 'BinaryMaskReader')

A reader object can be constructed with the appropriate class by instantiating it 
with the file path::

    # instantiate a reader object for each of these specific files
    raster_reader = tif_reader('raster.tif', read_metadata=True)
    vector_mask_reader = shp_reader('vector_mask.shp', metadata=raster_reader.metadata)

The ``read_metadata`` argument will populate the ``metadata`` attribute of the reader 
object with the co-ordinate reference system and geo-transform of the raster (as 
implemented in `rasterio`_). This can then be passed to the vector reader to tell it 
which co-ordinate system and spatial resolution to use when rasterising the shapefile. 
If the mask is itself already a georeferenced ``.tif`` raster, this is obviously not 
necessary and the geospatial metadata can be read directly.

The dask arrays containing the raw image (or mask) data can then be constructed with the 
method :meth:`~gim_cv.interfaces.base.GeoArrayFileInterface.load_array`, for example:: 

    raster_reader.load_array()
    vector_mask_reader.load_array()

This will assign the corresponding dask arrays to the ``array`` attributes, at which point 
preprocessing can be performed.

Limitations
^^^^^^^^^^^

One current limitation of the shapefile interface is that the rasterised array created from 
the shapefile must fit in RAM. This means that if you have a very large training dataset, 
consisting of a (set of) large RGB raster(s), there is a possibility of blowing up memory.

This can be circumvented by first `rasterising the shapefile with GDAL 
<https://gdal.org/programs/gdal_rasterize.html>`_ and using an explicit ``.tif``  mask raster.
This is because raster reading is implemented with dask (and thus out-of-core chunkwise 
computations are the norm) while shape reading is implemented with the GDAL python bindings. 

A permanent solution to this would be to implement out-of-core shapefile reading with Dask. 
See :ref:`inference dev notes`.

.. _rasterio: https://rasterio.readthedocs.io/en/latest/

Writing files
-------------

The same interface classes can be used to write an array (a segmentation mask 
generated by a model) to a raster file. Directly writing to shape is not supported 
yet, but can be done with a small amount of effort (see :doc:`polygonisation`). 
For example::

    # get the appropriate interface class for writing a binary tif mask
    tif_writer = get_interface('output_mask.tif', 'BinaryMaskWriter')
    # instantiate mask writer - this inherits the geospatial metadata from the 
    # image consumed by the model to create it
    mask_writer = tif_writer('output_mask.tif', metadata=raster_reader.metadata)
    # assign the array to be written out (a dask array, generated by a model)
    mask_writer.array = inferred_mask
    # write out the mask to the tif file
    mask_writer.write_raster(overwrite=False)


.. _inference dev notes:

Developer Notes
---------------

Migrating interfaces to rioxarray and geocube
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Some time during the writing of this library the tools `rioxarray`_ and `geocube`_ 
rose out of obscurity and became promising interfaces for general geospatial raster and 
vector files (among other things).

The former is built on `rasterio`_ (like the main ``.tif`` and ``.jp2`` 
interfaces native to this library) and `xarray`_, and has native dask support. This 
could quite easily replace the raster file <-> dask array interface code in this 
library while being more concise and actively developed by a community. For example::

    import rioxarray as rx

    raster_array = rx.open_rasterio('raster.tif', chunks=(5120, 5120))

Builds an xarray object equipped with various geospatial methods (reprojection, crs 
transformations, cutting by polygons etc.) tied to an underlying dask array 
accessible through the ``data`` attribute.

`geocube`_ provides a convenient API for rasterising vector files through its 
``make_geocube`` function which builds an xarray object tied to a numpy array 
from a vector file which can be in various formats (shapefile, geopackage, 
geojson etc.). It does not have native dask support, but I have opened `a ticket`_ 
about this and don't believe it would be too difficult to implement for someone who 
understands dask reasonably well.

Used together these might replace the interfaces submodule with a more convenient 
API in future.

You can see some examples of how these libraries can be used in the notebooks 
directory of the source code.

Out-of-core shapefile rasterisation
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

For out-of-core (larger than memory) shapefile rasterisation, an easier short-term 
alternative to the strategy outlined above (using geocube and implementing dask 
support) may be to reimplement :func:`gim_cv.interfaces.shp.ogr.rasterise_shapefile` 
to use a ``dask.delayed`` wrapper around GDAL with smaller spatial chunks to define a lazy 
raster.

Multi-class segmentation
^^^^^^^^^^^^^^^^^^^^^^^^

The interfaces module is where the lion's share of the necessary work is for fully implementing 
multi-class segmentation.

Multi-class segmentation should already be largely possible if one sticks to datasets with 
``.tif`` format pre-rasterised masks, and defines preprocessing pipelines to correctly 
separate the different classes over the channel dimension.

To implement it for datasets with shapefile masks one need to add logic for distinguishing different 
polygon features by the relevant properties that determine their class. As it stands this would 
require extending the :mod:`gim_cv.interfaces.shp` submodule, in particular adding logic to
:func:`gim_cv.interfaces.shp.ogr.rasterise_shapefile` such that different features are written to 
different bands.

This should also be possible and reasonably simple if masks are rasterised using geocube.

My recommendation would be to add a ``geocube`` submodule to :mod:`gim_cv.interfaces.shp`, implement 
dask support and separation of different features into raster bands in one go.

.. _a ticket: https://github.com/corteva/geocube/issues/41

.. _xarray: https://xarray.pydata.org/en/stable/

.. _rioxarray: https://corteva.github.io/rioxarray/stable/

.. _geocube: https://corteva.github.io/geocube/stable/

.. _Dask arrays: https://docs.dask.org/en/latest/array.html